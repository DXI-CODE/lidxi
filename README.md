# Desarrollo de Guante Inteligente Motriz-Sonoro de Apoyo para Individuos No Verbales Empleando Lenguaje de Señas Mexicano para Comunicación en Tiempo Real con Conectividad Híbrida

## Introducción

En el campo de los sistemas embebidos, el desarrollo de dispositivos inteligentes ha permitido la creación de herramientas avanzadas que mejoran la accesibilidad y la comunicación. Una de las aplicaciones más innovadoras en este ámbito es el desarrollo de tecnologías portátiles, como los guantes inteligentes, que integran sensores, procesamiento de señales y modelos de aprendizaje automático para interpretar gestos en tiempo real.

En este contexto, el presente trabajo propone el diseño e implementación de un guante inteligente capaz de reconocer y traducir el **Lenguaje de Señas Mexicano (LSM)** a salida de audio, facilitando la comunicación para individuos no verbales.  
El dispositivo empleará una arquitectura de **sistema embebido autónomo**, es decir, funcionará sin depender de una conexión a Internet, garantizando su uso en cualquier entorno. Sin embargo, permitirá **actualizaciones mediante conectividad híbrida**, asegurando mejoras en el reconocimiento de nuevas palabras y frases.

Para su desarrollo, se utilizarán **sensores inerciales y de flexión** para capturar los movimientos de la mano, procesados mediante algoritmos de **aprendizaje automático** embebidos en el sistema.

En las primeras etapas del proyecto, el guante será capaz de reconocer las **vocales**, evolucionando posteriormente al **abecedario completo** y, en una fase más avanzada, a **frases estructuradas**. Todo esto con ayuda de sensores de flexión [3], los cuales medirán los movimientos de la mano para su posterior procesamiento junto con un **algoritmo de aprendizaje supervisado** [4], capaz de reconocer diferentes gestos y transformarlos en audio.

Además, se integrará un **sistema de síntesis de voz**, que permitirá a personas con discapacidad auditiva y visual recibir una salida sonora del mensaje interpretado. Este enfoque combina **hardware especializado, procesamiento en tiempo real y modelos de IA** para proporcionar una solución innovadora y accesible en el ámbito de la comunicación asistida.

El objetivo de este trabajo es implementar técnicas de **aprendizaje automático** para desarrollar un modelo de **red neuronal** capaz de detectar y reconocer gestos específicos del LSM en tiempo real. Esto se logrará utilizando modelos de **aprendizaje profundo**, similares a los utilizados en la detección de objetos en imágenes, optimizados para interpretar los datos de los sensores y traducirlos en una señal de salida.

## Impacto Social

Este proyecto tiene un impacto **social significativo**, ya que busca brindar apoyo a **grupos históricamente rezagados**, como lo es la comunidad sordomuda, ayudándoles a superar su necesidad esencial de comunicarse con el resto de la sociedad.  
Adicionalmente, el guante puede servir como **herramienta educativa**, fomentando la difusión del **Lenguaje de Señas Mexicano (LSM)** entre la población en general.

---

> Créditos: 
> [Karla Guadalupe](githut.com/karlausuarioooo)
> [Mariana Palacios](github.com/mmarianausuariiooo)
> [Jeycson Gabriel](github.com/jeycsonusuariiooo)
> [Joan Pablo](github.com/JoanGarfias)
> [Jeovani Pacheco](](github.com/jeovaniiyusuarioo))
